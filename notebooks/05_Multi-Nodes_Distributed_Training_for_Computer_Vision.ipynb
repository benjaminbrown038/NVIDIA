{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Multi-Nodes Distributed Training for Computer Vision\n",
    "\n",
    "In this notebook, we will learn how to train a simple Image Classifier in distributed mode.\n",
    "We will first implement a vanilla pipeline parallel distribution. Then, we will use Microsoft's [DeepSpeed Library](https://www.deepspeed.ai/) for model distribution and optimization techniques.\n",
    "\n",
    "## The goals\n",
    "\n",
    "The goals of this notebook are to:\n",
    "* Learn how to train a vanilla CNN\n",
    "* Port the code to DeepSpeed library \n",
    "* Scale training using Data parallel distribution\n",
    "* Optimize training with DeepSpeed autotuning and Zero Redundancy Optimizer\n",
    "\n",
    "\n",
    "**[5.1 Convolutional Neural Network for Image Classification on CIFAR-10](#1.1-The-hardware-overview)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.1.1 The dataset](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.1.2 Convolutional Neural Network](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.1.3 Naive Model Distribution](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "**[5.2 Distributed Training with DeepSpeed](#1.1-The-hardware-overview)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.1 Make the code run with DeepSpeed](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.2 Scale-out training with Data Parallelism](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.3 Zero Redundancy Optimizer ](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "\n",
    "### Cancel Previous Running/Pending Jobs\n",
    "\n",
    "Before moving on, check that no jobs are still running or waiting on the SLURM queue. Let's check the SLURM jobs queue by executing the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are still jobs running or pending, execute the following cell to cancel all the user's jobs using the `scancel` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "!scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.1 Convolutional Neural Network for Image Classification on CIFAR-10\n",
    "\n",
    "## 5.1.1 The dataset\n",
    "\n",
    "\n",
    "The [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60K images (50K for training and 10K for testing). Images are 32 by 32 pixels labelled with 10 classes: plane, car, bird, cat, deer, dog, frog, horse, ship and truck. \n",
    "In this lab, we will train a simple Convolutional Neural Network to classify CIFAR-10 images.\n",
    "\n",
    "To download the dataset, we will use the [Torchvision](https://pytorch.org/vision/stable/index.html) package, a Pytorch library that contains popular datasets, model architectures, and common image transformations for Computer Vision.\n",
    "<img src=\"images/CIFAR-10.jpg\" width=\"350\" />\n",
    "\n",
    "Let's first import the relevant libraries by executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import display_html\n",
    "\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "\n",
    "# define an image transform \n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next 2 cells to download the training and test CIFAR10 corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc2a440dbf24703a6b2c23a2e4f59e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "# Download the CIFAR10 training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download the CIFAR10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show some random training images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(images, labels):\n",
    "    for i in range(8): \n",
    "        img = images[i] / 2 + 0.5\n",
    "        npimg = img.numpy()\n",
    "        plt.subplot(2,4,i+1)\n",
    "        plt.imshow(np.transpose(npimg, (1, 2 , 0)));\n",
    "        plt.axis('off');\n",
    "        plt.title(classes[labels[i]])\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# get some training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "# Show images\n",
    "imshow(images,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 Convolutional Neural Network\n",
    "\n",
    "Let's define a neural network with 2 convolutional layers, first followed by a pooling layer then 3 fully connected layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "cnn_net = CNN_Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the model to GPU 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the Convolutional Neural Network\n",
    "from torchsummary import summary\n",
    "summary(cnn_net,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the optimizer and hyperparameters. We will use the Stochastic Gradient Descent (SGD) with momentum optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_net.parameters(), lr=0.001,momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# Tensorboard event recording directory \n",
    "writer = SummaryWriter('megatron/tensorboard/cifar10')\n",
    "\n",
    "log_interval=100\n",
    "batch_size=64\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0, iterations   100] loss: 2.305 accuracy: 8.781250 %\n",
      "[epoch 0, iterations   200] loss: 2.304 accuracy: 9.312500 %\n",
      "[epoch 0, iterations   300] loss: 2.304 accuracy: 9.635417 %\n",
      "[epoch 0, iterations   400] loss: 2.303 accuracy: 10.128906 %\n",
      "[epoch 0, iterations   500] loss: 2.301 accuracy: 10.334375 %\n",
      "[epoch 0, iterations   600] loss: 2.302 accuracy: 10.294271 %\n",
      "[epoch 0, iterations   700] loss: 2.301 accuracy: 10.310268 %\n",
      "[epoch 0, iterations   782] loss: 2.300 accuracy: 10.570000 %\n",
      "[epoch 1, iterations   100] loss: 2.298 accuracy: 14.640625 %\n",
      "[epoch 1, iterations   200] loss: 2.296 accuracy: 15.351562 %\n",
      "[epoch 1, iterations   300] loss: 2.294 accuracy: 15.505208 %\n",
      "[epoch 1, iterations   400] loss: 2.290 accuracy: 15.699219 %\n",
      "[epoch 1, iterations   500] loss: 2.284 accuracy: 16.240625 %\n",
      "[epoch 1, iterations   600] loss: 2.272 accuracy: 16.888021 %\n",
      "[epoch 1, iterations   700] loss: 2.247 accuracy: 17.296875 %\n",
      "[epoch 1, iterations   782] loss: 2.202 accuracy: 17.760000 %\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "        \n",
    "        # print the loss and accuracy metrics log_interval mini-batches\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        if i % log_interval == (log_interval - 1):  \n",
    "            print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / log_interval, 100.*correct/total))\n",
    "            writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / log_interval, i + 1)\n",
    "            writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "            running_loss = 0.0\n",
    "    # print the last iterations \n",
    "    print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / ((i % log_interval) + 1), 100.*correct/total))\n",
    "    writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / ((i % log_interval) + 1), i + 1)\n",
    "    writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "\n",
    "print('Training Done')\n",
    "writer.add_graph(cnn_net, inputs)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Training and Inspect the Model on Tensorboard \n",
    "\n",
    "We set the arguments for recording Tensorboard events in the previous CNN training. The training loss is available under the name `cifar10`. We can also visualize the model and navigate throughout its layers on the \"Graphs\" tab.\n",
    "\n",
    "<img src=\"images/CNN.png\" width=\"750\"/>\n",
    "\n",
    "Execute the next cell to create a link to Tensorboard for your browser. Then, click the link to see graphs of experiment metrics saved in the specified `Tensorboard` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const href = window.location.hostname +'/tensorboard/';\n",
       "let a = document.createElement('a');\n",
       "let link = document.createTextNode('Open Tensorboard!');\n",
       "a.appendChild(link);\n",
       "a.href = \"http://\" + href;\n",
       "a.style.color = \"navy\"\n",
       "a.target = \"_blank\"\n",
       "element.append(a);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Trained Model\n",
    "\n",
    "Let's evaluate the trained model on the CIFAR-10 test dataset. Execute the following cell to evaluate the accuracy on the test set. Accuracy detail per class will also be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 22.100000 %\n",
      "Accuracy of plane : 35.714286 %\n",
      "Accuracy of   car : 36.000000 %\n",
      "Accuracy of  bird : 0.000000 %\n",
      "Accuracy of   cat : 0.000000 %\n",
      "Accuracy of  deer : 0.000000 %\n",
      "Accuracy of   dog : 16.949153 %\n",
      "Accuracy of  frog : 60.714286 %\n",
      "Accuracy of horse : 17.187500 %\n",
      "Accuracy of  ship : 60.344828 %\n",
      "Accuracy of truck : 15.384615 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cnn_net(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        c = (predicted == labels.to(device)).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %2f %%' %\n",
    "      (100 * correct / total))\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2f %%' %\n",
    "          (classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.3 Naive Model Distribution\n",
    "\n",
    "Let's now implement a naive pipeline parallel distribution of the previous CNN model. To do so, we need to explicitly place each layer into the device and implement the forward pass, accordingly moving the corresponding outputs to match devices accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will run the CNN model on two GPUs by placing: conv1 + pooling on GPU0 and conv2 + fc1 + fc2+ fc3 on GPU1. \n",
    "We will use torch *[TORCH.TENSOR.TO](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to)* to convert tensors to cuda and place them to the desired device. \n",
    "\n",
    "Have a look at modified class on the defined `Net_Parallel` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net_Parallel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_Parallel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5).to('cuda:0')               # Changed here\n",
    "        self.pool = nn.MaxPool2d(2, 2).to('cuda:0')                # Changed here\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).to('cuda:1')              # Changed here\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120).to('cuda:1')         # Changed here\n",
    "        self.fc2 = nn.Linear(120, 84).to('cuda:1')                 # Changed here\n",
    "        self.fc3 = nn.Linear(84, 10).to('cuda:1')                  # Changed here\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x.to('cuda:0'))))          # Changed here\n",
    "        x = self.pool(F.relu(self.conv2(x.to('cuda:1'))))          # Changed here\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "cnn_net_pp = Net_Parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous training execution, run the next 2 cells to define the optimizer/hyperparameters and then launch the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_net_pp.parameters(), lr=0.001,momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# Tensorboard event recording directory \n",
    "writer_pp = SummaryWriter('megatron/tensorboard/cifar10_PP')                 \n",
    "\n",
    "log_interval=100\n",
    "batch_size=64\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the GPUs activity by running the next cell to open a terminal and the watch `nvidia-smi` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<pre>\n",
       "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
       "   Step 2: Check the GPUs: <font color=\"green\">watch nvidia-smi</font>\n",
       "</pre\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<pre>\n",
    "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
    "   Step 2: Check the GPUs: <font color=\"green\">watch nvidia-smi</font>\n",
    "</pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the terminal window opened and execute the next training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:271: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0, iterations   100] loss: 2.304 accuracy: 9.781250 %\n",
      "[epoch 0, iterations   200] loss: 2.302 accuracy: 10.085938 %\n",
      "[epoch 0, iterations   300] loss: 2.301 accuracy: 10.218750 %\n",
      "[epoch 0, iterations   400] loss: 2.298 accuracy: 10.304688 %\n",
      "[epoch 0, iterations   500] loss: 2.294 accuracy: 10.668750 %\n",
      "[epoch 0, iterations   600] loss: 2.288 accuracy: 11.161458 %\n",
      "[epoch 0, iterations   700] loss: 2.276 accuracy: 11.794643 %\n",
      "[epoch 0, iterations   782] loss: 2.264 accuracy: 12.312000 %\n",
      "[epoch 1, iterations   100] loss: 2.237 accuracy: 18.890625 %\n",
      "[epoch 1, iterations   200] loss: 2.199 accuracy: 19.140625 %\n",
      "[epoch 1, iterations   300] loss: 2.142 accuracy: 20.072917 %\n",
      "[epoch 1, iterations   400] loss: 2.111 accuracy: 21.113281 %\n",
      "[epoch 1, iterations   500] loss: 2.075 accuracy: 22.025000 %\n",
      "[epoch 1, iterations   600] loss: 2.032 accuracy: 22.640625 %\n",
      "[epoch 1, iterations   700] loss: 2.000 accuracy: 23.388393 %\n",
      "[epoch 1, iterations   782] loss: 1.968 accuracy: 23.890000 %\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN with pipeline parallel\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_net_pp(inputs.to('cuda:0'))                                # Changed here\n",
    "        loss = criterion(outputs, labels.to('cuda:1'))                           # Changed here\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.reset_max_memory_allocated(0)\n",
    "        # print the loss and accuracy metrics log_interval mini-batches\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.to('cuda:1')).sum().item()                 # Changed here\n",
    "        if i % log_interval == (log_interval - 1):  \n",
    "            print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / log_interval, 100.*correct/total))\n",
    "            writer_pp.add_scalar(\"Training Cross Entropy Loss\", running_loss / log_interval, i + 1)\n",
    "            writer_pp.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "            running_loss = 0.0\n",
    "    # print the last iterations \n",
    "    print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / ((i % log_interval) + 1), 100.*correct/total))\n",
    "    writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / ((i % log_interval) + 1), i + 1)\n",
    "    writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "\n",
    "print('Training Done')\n",
    "writer_pp.add_graph(cnn_net_pp, inputs)\n",
    "writer_pp.flush()\n",
    "writer_pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Distributed Training with DeepSpeed\n",
    "\n",
    "The DeepSpeed library is a Deep Learning optimization library for distributed training on several different hardware sizes ranging from a single GPU to low-end clusters, going up to massive supercomputers.\n",
    "\n",
    "<img src=\"https://www.deepspeed.ai/assets/images/3d-parallelism.png\" width=\"650\" />\n",
    "\n",
    "\n",
    "- Distributed Training with Mixed Precision on Single-GPU/Multi-GPU/Multi-Node\n",
    "- Pipeline Parallelism and an integration with Megatron-LM tensor parallel \n",
    "- Zero Redundancy Optimizer (ZeRO): Memory optimization techniques\n",
    "- ZeRO-Offload: Offloading data and compute to the CPU\n",
    "- Mixture of Experts (MoE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 Make the code run with DeepSpeed\n",
    "\n",
    "The DeepSpeed engine can wrap neural networks defined as `torch.nn.module`. To write the previous Model with DeepSpeed, we will need to:\n",
    "\n",
    "- Instantiate the DeepSpeed Model engine and optimizer: Use the DeepSpeed initializer as follows: \n",
    "`model_engine, optimizer= deepspeed.initialize(args=args, model=Your_Network, model_parameters=parameters, training_data=trainset)`\n",
    "- The variable `args` should embed training arguments and the DeepSpeed arguments. We can use `deepspeed.add_config_arguments(parser)` to add the DeepSpeed arguments to our parser.\n",
    "- Refer to the deepspeed `model_engine` instead of `Your_Network` in the rest of the code.\n",
    "- For distributed training implementation with `torch.distributed.init_process_group(...)`, replace that with `deepspeed.init_distributed()`\n",
    "\n",
    "Learn more on how to write DeepSpeed models with the [dedicated DeepSpeed documentation.](https://www.deepspeed.ai/getting-started/#writing-deepspeed-models) \n",
    "\n",
    "DeepSpeed arguments can be passed throughout a JSON configuration file. Let's have a look at our the DeepSpeed configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_batch_size\": 16,\n",
      "  \"steps_per_print\": 2000,\n",
      "  \"optimizer\": {\n",
      "    \"type\": \"Adam\",\n",
      "    \"params\": {\n",
      "      \"lr\": 0.001,\n",
      "      \"betas\": [\n",
      "        0.8,\n",
      "        0.999\n",
      "      ],\n",
      "      \"eps\": 1e-8,\n",
      "      \"weight_decay\": 3e-7\n",
      "    }\n",
      "  },\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"WarmupLR\",\n",
      "    \"params\": {\n",
      "      \"warmup_min_lr\": 0,\n",
      "      \"warmup_max_lr\": 0.001,\n",
      "      \"warmup_num_steps\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"gradient_clipping\": 1.0,\n",
      "  \"prescale_gradients\": false,\n",
      "  \"fp16\": {\n",
      "      \"enabled\": true,\n",
      "      \"fp16_master_weights_and_grads\": false,\n",
      "      \"loss_scale\": 0,\n",
      "      \"loss_scale_window\": 500,\n",
      "      \"hysteresis\": 2,\n",
      "      \"min_loss_scale\": 1,\n",
      "      \"initial_scale_power\": 15\n",
      "  },\n",
      "  \"wall_clock_breakdown\": false,\n",
      "  \"zero_optimization\": {\n",
      "      \"stage\": 0,\n",
      "      \"allgather_partitions\": true,\n",
      "      \"reduce_scatter\": true,\n",
      "      \"allgather_bucket_size\": 50000000,\n",
      "      \"reduce_bucket_size\": 50000000,\n",
      "      \"overlap_comm\": true,\n",
      "      \"contiguous_gradients\": true,\n",
      "      \"cpu_offload\": false\n",
      "  } \n",
      "\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Have a look at the DeepSpeed config\n",
    "!cat code/moe/ds_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant library\n",
    "import deepspeed\n",
    "\n",
    "# define the argument class, the training arguments, and DeepSpeed\n",
    "class Args:\n",
    "    log_interval=100 \n",
    "    batch_size=64\n",
    "    epochs=2\n",
    "    deepspeed = True\n",
    "    deepspeed_config = \"code/moe/ds_config.json\"\n",
    "    local_rank= 0\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-27 15:01:01,928] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.5, git-hash=unknown, git-branch=unknown\n",
      "[2023-06-27 15:01:01,929] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...\n",
      "[2023-06-27 15:01:02,146] [INFO] [distributed.py:85:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.18.0.5, master_port=29500\n",
      "[2023-06-27 15:01:02,149] [INFO] [distributed.py:48:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2023-06-27 15:01:02,410] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Creating extension directory /home/admin/.cache/torch_extensions/py38_cu115/fused_adam...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/admin/.cache/torch_extensions/py38_cu115/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -I/opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/adam -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -std=c++14 -c /opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
      "[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -I/opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/adam -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
      "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 17.697773456573486 seconds\n",
      "[2023-06-27 15:01:20,676] [INFO] [engine.py:1100:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
      "[2023-06-27 15:01:20,676] [INFO] [engine.py:1108:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2023-06-27 15:01:20,677] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n",
      "[2023-06-27 15:01:20,679] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
      "[2023-06-27 15:01:20,679] [INFO] [engine.py:785:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2023-06-27 15:01:20,680] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f81b4745910>\n",
      "[2023-06-27 15:01:20,680] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
      "[2023-06-27 15:01:20,681] [INFO] [config.py:1059:print] DeepSpeedEngine configuration:\n",
      "[2023-06-27 15:01:20,681] [INFO] [config.py:1063:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-06-27 15:01:20,682] [INFO] [config.py:1063:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-06-27 15:01:20,682] [INFO] [config.py:1063:print]   amp_enabled .................. False\n",
      "[2023-06-27 15:01:20,682] [INFO] [config.py:1063:print]   amp_params ................... False\n",
      "[2023-06-27 15:01:20,683] [INFO] [config.py:1063:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": null, \n",
      "    \"exps_dir\": null, \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-06-27 15:01:20,683] [INFO] [config.py:1063:print]   bfloat16_enabled ............. False\n",
      "[2023-06-27 15:01:20,684] [INFO] [config.py:1063:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-06-27 15:01:20,684] [INFO] [config.py:1063:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-06-27 15:01:20,684] [INFO] [config.py:1063:print]   communication_data_type ...... None\n",
      "[2023-06-27 15:01:20,685] [INFO] [config.py:1063:print]   curriculum_enabled ........... False\n",
      "[2023-06-27 15:01:20,685] [INFO] [config.py:1063:print]   curriculum_params ............ False\n",
      "[2023-06-27 15:01:20,685] [INFO] [config.py:1063:print]   dataloader_drop_last ......... False\n",
      "[2023-06-27 15:01:20,686] [INFO] [config.py:1063:print]   disable_allgather ............ False\n",
      "[2023-06-27 15:01:20,686] [INFO] [config.py:1063:print]   dump_state ................... False\n",
      "[2023-06-27 15:01:20,686] [INFO] [config.py:1063:print]   dynamic_loss_scale_args ...... {'init_scale': 32768, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2023-06-27 15:01:20,687] [INFO] [config.py:1063:print]   eigenvalue_enabled ........... False\n",
      "[2023-06-27 15:01:20,687] [INFO] [config.py:1063:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-06-27 15:01:20,687] [INFO] [config.py:1063:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-06-27 15:01:20,687] [INFO] [config.py:1063:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-06-27 15:01:20,688] [INFO] [config.py:1063:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-06-27 15:01:20,688] [INFO] [config.py:1063:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-06-27 15:01:20,688] [INFO] [config.py:1063:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-06-27 15:01:20,689] [INFO] [config.py:1063:print]   eigenvalue_verbose ........... False\n",
      "[2023-06-27 15:01:20,689] [INFO] [config.py:1063:print]   elasticity_enabled ........... False\n",
      "[2023-06-27 15:01:20,689] [INFO] [config.py:1063:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-06-27 15:01:20,690] [INFO] [config.py:1063:print]   fp16_enabled ................. True\n",
      "[2023-06-27 15:01:20,690] [INFO] [config.py:1063:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-06-27 15:01:20,690] [INFO] [config.py:1063:print]   fp16_mixed_quantize .......... False\n",
      "[2023-06-27 15:01:20,691] [INFO] [config.py:1063:print]   global_rank .................. 0\n",
      "[2023-06-27 15:01:20,691] [INFO] [config.py:1063:print]   gradient_accumulation_steps .. 1\n",
      "[2023-06-27 15:01:20,691] [INFO] [config.py:1063:print]   gradient_clipping ............ 1.0\n",
      "[2023-06-27 15:01:20,692] [INFO] [config.py:1063:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-06-27 15:01:20,692] [INFO] [config.py:1063:print]   initial_dynamic_scale ........ 32768\n",
      "[2023-06-27 15:01:20,692] [INFO] [config.py:1063:print]   loss_scale ................... 0\n",
      "[2023-06-27 15:01:20,693] [INFO] [config.py:1063:print]   memory_breakdown ............. False\n",
      "[2023-06-27 15:01:20,693] [INFO] [config.py:1063:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-06-27 15:01:20,693] [INFO] [config.py:1063:print]   optimizer_name ............... adam\n",
      "[2023-06-27 15:01:20,694] [INFO] [config.py:1063:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
      "[2023-06-27 15:01:20,694] [INFO] [config.py:1063:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-06-27 15:01:20,694] [INFO] [config.py:1063:print]   pld_enabled .................. False\n",
      "[2023-06-27 15:01:20,695] [INFO] [config.py:1063:print]   pld_params ................... False\n",
      "[2023-06-27 15:01:20,695] [INFO] [config.py:1063:print]   prescale_gradients ........... False\n",
      "[2023-06-27 15:01:20,695] [INFO] [config.py:1063:print]   quantize_change_rate ......... 0.001\n",
      "[2023-06-27 15:01:20,696] [INFO] [config.py:1063:print]   quantize_groups .............. 1\n",
      "[2023-06-27 15:01:20,696] [INFO] [config.py:1063:print]   quantize_offset .............. 1000\n",
      "[2023-06-27 15:01:20,696] [INFO] [config.py:1063:print]   quantize_period .............. 1000\n",
      "[2023-06-27 15:01:20,697] [INFO] [config.py:1063:print]   quantize_rounding ............ 0\n",
      "[2023-06-27 15:01:20,697] [INFO] [config.py:1063:print]   quantize_start_bits .......... 16\n",
      "[2023-06-27 15:01:20,697] [INFO] [config.py:1063:print]   quantize_target_bits ......... 8\n",
      "[2023-06-27 15:01:20,697] [INFO] [config.py:1063:print]   quantize_training_enabled .... False\n",
      "[2023-06-27 15:01:20,698] [INFO] [config.py:1063:print]   quantize_type ................ 0\n",
      "[2023-06-27 15:01:20,698] [INFO] [config.py:1063:print]   quantize_verbose ............. False\n",
      "[2023-06-27 15:01:20,698] [INFO] [config.py:1063:print]   scheduler_name ............... WarmupLR\n",
      "[2023-06-27 15:01:20,699] [INFO] [config.py:1063:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n",
      "[2023-06-27 15:01:20,699] [INFO] [config.py:1063:print]   sparse_attention ............. None\n",
      "[2023-06-27 15:01:20,699] [INFO] [config.py:1063:print]   sparse_gradients_enabled ..... False\n",
      "[2023-06-27 15:01:20,700] [INFO] [config.py:1063:print]   steps_per_print .............. 2000\n",
      "[2023-06-27 15:01:20,700] [INFO] [config.py:1063:print]   tensorboard_enabled .......... False\n",
      "[2023-06-27 15:01:20,700] [INFO] [config.py:1063:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2023-06-27 15:01:20,701] [INFO] [config.py:1063:print]   tensorboard_output_path ...... \n",
      "[2023-06-27 15:01:20,701] [INFO] [config.py:1063:print]   train_batch_size ............. 16\n",
      "[2023-06-27 15:01:20,701] [INFO] [config.py:1063:print]   train_micro_batch_size_per_gpu  16\n",
      "[2023-06-27 15:01:20,702] [INFO] [config.py:1063:print]   use_quantizer_kernel ......... False\n",
      "[2023-06-27 15:01:20,702] [INFO] [config.py:1063:print]   wall_clock_breakdown ......... False\n",
      "[2023-06-27 15:01:20,702] [INFO] [config.py:1063:print]   world_size ................... 1\n",
      "[2023-06-27 15:01:20,703] [INFO] [config.py:1063:print]   zero_allow_untested_optimizer  False\n",
      "[2023-06-27 15:01:20,703] [INFO] [config.py:1063:print]   zero_config .................. {\n",
      "    \"stage\": 0, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.000000e+07, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+07, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": false, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": null, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_16bit_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2023-06-27 15:01:20,703] [INFO] [config.py:1063:print]   zero_enabled ................. False\n",
      "[2023-06-27 15:01:20,704] [INFO] [config.py:1063:print]   zero_optimization_stage ...... 0\n",
      "[2023-06-27 15:01:20,704] [INFO] [config.py:1065:print]   json = {\n",
      "    \"train_batch_size\": 16, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.001, \n",
      "            \"betas\": [0.8, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 3e-07\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.001, \n",
      "            \"warmup_num_steps\": 1000\n",
      "        }\n",
      "    }, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"prescale_gradients\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"fp16_master_weights_and_grads\": false, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 500, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1, \n",
      "        \"initial_scale_power\": 15\n",
      "    }, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 0, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"allgather_bucket_size\": 5.000000e+07, \n",
      "        \"reduce_bucket_size\": 5.000000e+07, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"cpu_offload\": false\n",
      "    }\n",
      "}\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Creating extension directory /home/admin/.cache/torch_extensions/py38_cu115/utils...\n",
      "Emitting ninja build file /home/admin/.cache/torch_extensions/py38_cu115/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -c /opt/conda/lib/python3.8/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n",
      "[2/2] c++ flatten_unflatten.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 9.432605028152466 seconds\n"
     ]
    }
   ],
   "source": [
    "# define the CNN network\n",
    "cnn_net_ds = CNN_Net()\n",
    "\n",
    "# Define the hyperparameters\n",
    "parameters = filter(lambda p: p.requires_grad, cnn_net_ds.parameters())\n",
    "\n",
    "# Wrap the CNN network with DeepSpeed\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(args=args, model=cnn_net_ds, model_parameters=parameters, training_data=trainset)\n",
    "\n",
    "# enable mixed precision\n",
    "fp16 = model_engine.fp16_enabled()\n",
    "\n",
    "device = model_engine.local_rank\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Tensorboard event recording directory \n",
    "writer_ds = SummaryWriter('megatron/tensorboard/cifar10_DS')                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0, iterations   100] loss: 2.124 accuracy: 20.328125 %\n",
      "[epoch 0, iterations   200] loss: 1.842 accuracy: 26.171875 %\n",
      "[epoch 0, iterations   300] loss: 1.702 accuracy: 29.770833 %\n",
      "[epoch 0, iterations   400] loss: 1.627 accuracy: 32.460938 %\n",
      "[epoch 0, iterations   500] loss: 1.583 accuracy: 34.406250 %\n",
      "[2023-06-27 15:01:35,387] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:01:35,388] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 32768 to 65536\n",
      "[2023-06-27 15:01:35,394] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 501\n",
      "[2023-06-27 15:01:35,394] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0\n",
      "[2023-06-27 15:01:35,395] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
      "[epoch 0, iterations   600] loss: 1.555 accuracy: 35.929688 %\n",
      "[epoch 0, iterations   700] loss: 1.513 accuracy: 37.214286 %\n",
      "[epoch 0, iterations   782] loss: 1.468 accuracy: 38.238000 %\n",
      "[epoch 1, iterations   100] loss: 1.460 accuracy: 47.437500 %\n",
      "[epoch 1, iterations   200] loss: 1.447 accuracy: 47.804688 %\n",
      "[2023-06-27 15:01:38,133] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:01:38,134] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n",
      "[2023-06-27 15:01:38,139] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1003\n",
      "[2023-06-27 15:01:38,140] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n",
      "[2023-06-27 15:01:38,140] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
      "[epoch 1, iterations   300] loss: 1.428 accuracy: 47.958333 %\n",
      "[epoch 1, iterations   400] loss: 1.385 accuracy: 48.410156 %\n",
      "[epoch 1, iterations   500] loss: 1.383 accuracy: 48.821875 %\n",
      "[epoch 1, iterations   600] loss: 1.365 accuracy: 49.179688 %\n",
      "[epoch 1, iterations   700] loss: 1.351 accuracy: 49.428571 %\n",
      "[2023-06-27 15:01:40,619] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:01:40,620] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n",
      "[2023-06-27 15:01:40,624] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1505\n",
      "[2023-06-27 15:01:40,624] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n",
      "[2023-06-27 15:01:40,625] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
      "[epoch 1, iterations   782] loss: 1.307 accuracy: 49.790000 %\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN with DeepSpeed\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        if fp16:\n",
    "            inputs = inputs.half()        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_engine(inputs)             # Changed net_cnn to model_engine\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        model_engine.backward(loss)                # Changed net_cnn to model_engine\n",
    "        model_engine.step()                        # Changed net_cnn to model_engine\n",
    "        \n",
    "        # print the loss and accuracy metrics log_interval mini-batches\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        if i % log_interval == (log_interval - 1):  \n",
    "            print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / log_interval, 100.*correct/total))\n",
    "            writer_ds.add_scalar(\"Training Cross Entropy Loss\", running_loss / log_interval, i + 1)\n",
    "            writer_ds.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # print the last iterations \n",
    "    print('[epoch %d, iterations %5d] loss: %.3f accuracy: %2f %%' %  (epoch , i + 1, running_loss / ((i % log_interval) + 1), 100.*correct/total))\n",
    "    writer.add_scalar(\"Training Cross Entropy Loss\", running_loss / ((i % log_interval) + 1), i + 1)\n",
    "    writer.add_scalar(\"Training Accuracy\", 100.*correct/total, i + 1)\n",
    "    \n",
    "print('Training Done')\n",
    "writer_ds.add_graph(model_engine, inputs)\n",
    "writer_ds.flush()\n",
    "writer_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous steps are aggregated into the python script [cifar10_deepspeed.py](./code/moe/cifar10_deepspeed.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 Scale-out training with Data Parallelism \n",
    "\n",
    "Let's now scale our previous training using distributed training techniques. To run the previous code on 4 GPUs using Data Parallel Distribution, instead of using torch.distributed.launch command, we can use deepspeed implementation.\n",
    "\n",
    "`python -m torch.distributed.launch --nproc_per_node=4 my_code.py <args>`\n",
    "\n",
    "With DeepSpeed, simply replace torch.distributed.launch with deepspeed and add a new argument --deepspeed ds_config.json\n",
    "\n",
    "`deepspeed --num_gpus=4 my_code.py  <args> --deepspeed ds_config.json`\n",
    "\n",
    "Execute the next cell to run the previous cifar10_deepspeed.py training code on 4 GPUs with DeepSpeed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kill zombie processes\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-27 15:03:06,596] [WARNING] [runner.py:159:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2023-06-27 15:03:06,779] [INFO] [runner.py:457:main] cmd = /opt/conda/bin/python3.8 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 /dli/code/moe/cifar10_deepspeed.py --deepspeed --deepspeed_config /dli/code/moe/ds_config.json --profile-execution=True --profile-name=zero0\n",
      "[2023-06-27 15:03:07,726] [INFO] [launch.py:96:main] 0 NCCL_P2P_DISABLE=1\n",
      "[2023-06-27 15:03:07,726] [INFO] [launch.py:96:main] 0 NCCL_VERSION=2.11.4\n",
      "[2023-06-27 15:03:07,726] [INFO] [launch.py:103:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}\n",
      "[2023-06-27 15:03:07,727] [INFO] [launch.py:109:main] nnodes=1, num_local_procs=4, node_rank=0\n",
      "[2023-06-27 15:03:07,727] [INFO] [launch.py:122:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})\n",
      "[2023-06-27 15:03:07,727] [INFO] [launch.py:123:main] dist_world_size=4\n",
      "[2023-06-27 15:03:07,727] [INFO] [launch.py:125:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[2023-06-27 15:03:10,194] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.5, git-hash=unknown, git-branch=unknown\n",
      "[2023-06-27 15:03:10,209] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.5, git-hash=unknown, git-branch=unknown\n",
      "[2023-06-27 15:03:10,210] [INFO] [distributed.py:48:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2023-06-27 15:03:10,232] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.5, git-hash=unknown, git-branch=unknown\n",
      "[2023-06-27 15:03:10,239] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.5, git-hash=unknown, git-branch=unknown\n",
      "[2023-06-27 15:03:13,097] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/admin/.cache/torch_extensions/py38_cu115/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.11005544662475586 seconds\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10233116149902344 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10206437110900879 seconds\n",
      "[2023-06-27 15:03:13,783] [INFO] [engine.py:1100:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
      "[2023-06-27 15:03:13,783] [INFO] [engine.py:1108:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2023-06-27 15:03:13,783] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "[2023-06-27 15:03:13,787] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
      "[2023-06-27 15:03:13,787] [INFO] [engine.py:785:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2023-06-27 15:03:13,787] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f020703b130>\n",
      "[2023-06-27 15:03:13,787] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
      "[2023-06-27 15:03:13,787] [INFO] [config.py:1059:print] DeepSpeedEngine configuration:\n",
      "[2023-06-27 15:03:13,787] [INFO] [config.py:1063:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-06-27 15:03:13,787] [INFO] [config.py:1063:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   amp_enabled .................. False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   amp_params ................... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": null, \n",
      "    \"exps_dir\": null, \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   bfloat16_enabled ............. False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   communication_data_type ...... None\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   curriculum_enabled ........... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   curriculum_params ............ False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   dataloader_drop_last ......... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   disable_allgather ............ False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   dump_state ................... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   dynamic_loss_scale_args ...... {'init_scale': 32768, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_enabled ........... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   eigenvalue_verbose ........... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   elasticity_enabled ........... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   fp16_enabled ................. True\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   fp16_mixed_quantize .......... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   global_rank .................. 0\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   gradient_accumulation_steps .. 1\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   gradient_clipping ............ 1.0\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   initial_dynamic_scale ........ 32768\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   loss_scale ................... 0\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   memory_breakdown ............. False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   optimizer_name ............... adam\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-06-27 15:03:13,788] [INFO] [config.py:1063:print]   pld_enabled .................. False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   pld_params ................... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   prescale_gradients ........... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_change_rate ......... 0.001\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_groups .............. 1\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_offset .............. 1000\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_period .............. 1000\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_rounding ............ 0\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_start_bits .......... 16\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_target_bits ......... 8\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_training_enabled .... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_type ................ 0\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   quantize_verbose ............. False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   scheduler_name ............... WarmupLR\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   sparse_attention ............. None\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   sparse_gradients_enabled ..... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   steps_per_print .............. 2000\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   tensorboard_enabled .......... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   tensorboard_output_path ...... \n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   train_batch_size ............. 16\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   train_micro_batch_size_per_gpu  4\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   use_quantizer_kernel ......... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   wall_clock_breakdown ......... False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   world_size ................... 4\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   zero_allow_untested_optimizer  False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   zero_config .................. {\n",
      "    \"stage\": 0, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.000000e+07, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+07, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": false, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": null, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_16bit_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   zero_enabled ................. False\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1063:print]   zero_optimization_stage ...... 0\n",
      "[2023-06-27 15:03:13,789] [INFO] [config.py:1065:print]   json = {\n",
      "    \"train_batch_size\": 16, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.001, \n",
      "            \"betas\": [0.8, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 3e-07\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.001, \n",
      "            \"warmup_num_steps\": 1000\n",
      "        }\n",
      "    }, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"prescale_gradients\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"fp16_master_weights_and_grads\": false, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 500, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1, \n",
      "        \"initial_scale_power\": 15\n",
      "    }, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 0, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"allgather_bucket_size\": 5.000000e+07, \n",
      "        \"reduce_bucket_size\": 5.000000e+07, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"cpu_offload\": false\n",
      "    }\n",
      "}\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/admin/.cache/torch_extensions/py38_cu115/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.20217013359069824 seconds\n",
      "Using /home/admin/.cache/torch_extensions/py38_cu115 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.1034553050994873 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10212850570678711 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10199785232543945 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.102020263671875 seconds\n",
      "[2023-06-27 15:03:16,640] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 81\n",
      "[2023-06-27 15:03:16,640] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 81\n",
      "[2023-06-27 15:03:16,640] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 81\n",
      "[2023-06-27 15:03:16,640] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 32768 to 16384.0\n",
      "[2023-06-27 15:03:16,640] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 32768 to 16384.0\n",
      "[2023-06-27 15:03:16,640] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 32768 to 16384.0\n",
      "[2023-06-27 15:03:16,641] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 81\n",
      "[2023-06-27 15:03:16,641] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 32768 to 16384.0\n",
      "[2023-06-27 15:03:16,641] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768, reducing to 16384.0\n",
      "[epoch 0, iterations   100] loss: 2.224 accuracy: 15.250000 %[epoch 0, iterations   100] loss: 2.238 accuracy: 13.500000 %\n",
      "\n",
      "[epoch 0, iterations   100] loss: 2.238 accuracy: 15.000000 %\n",
      "[epoch 0, iterations   100] loss: 2.272 accuracy: 14.000000 %\n",
      "[2023-06-27 15:03:17,046] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 172\n",
      "[2023-06-27 15:03:17,046] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 172\n",
      "[2023-06-27 15:03:17,046] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 172\n",
      "[2023-06-27 15:03:17,046] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
      "[2023-06-27 15:03:17,046] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
      "[2023-06-27 15:03:17,046] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
      "[2023-06-27 15:03:17,047] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 172\n",
      "[2023-06-27 15:03:17,047] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
      "[2023-06-27 15:03:17,047] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
      "[epoch 0, iterations   200] loss: 2.025 accuracy: 18.875000 %\n",
      "[epoch 0, iterations   200] loss: 2.103 accuracy: 17.500000 %\n",
      "[epoch 0, iterations   200] loss: 1.989 accuracy: 20.375000 %\n",
      "[epoch 0, iterations   200] loss: 2.003 accuracy: 19.375000 %\n",
      "[epoch 0, iterations   300] loss: 1.929 accuracy: 20.583333 %[epoch 0, iterations   300] loss: 1.927 accuracy: 21.916667 %\n",
      "\n",
      "[epoch 0, iterations   300] loss: 1.931 accuracy: 23.083333 %\n",
      "[epoch 0, iterations   300] loss: 1.885 accuracy: 22.833333 %\n",
      "[epoch 0, iterations   400] loss: 1.782 accuracy: 24.125000 %[epoch 0, iterations   400] loss: 1.839 accuracy: 24.062500 %\n",
      "\n",
      "[epoch 0, iterations   400] loss: 1.810 accuracy: 26.250000 %\n",
      "[epoch 0, iterations   400] loss: 1.833 accuracy: 24.937500 %\n",
      "[2023-06-27 15:03:18,489] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 496\n",
      "[2023-06-27 15:03:18,489] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 496\n",
      "[2023-06-27 15:03:18,489] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 496\n",
      "[2023-06-27 15:03:18,489] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:18,489] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:18,489] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:18,490] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 496\n",
      "[2023-06-27 15:03:18,490] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:18,490] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 0, iterations   500] loss: 1.680 accuracy: 26.500000 %[epoch 0, iterations   500] loss: 1.775 accuracy: 25.850000 %\n",
      "\n",
      "[epoch 0, iterations   500] loss: 1.720 accuracy: 28.250000 %\n",
      "[epoch 0, iterations   500] loss: 1.702 accuracy: 27.450000 %\n",
      "[epoch 0, iterations   600] loss: 1.665 accuracy: 28.375000 %\n",
      "[epoch 0, iterations   600] loss: 1.716 accuracy: 27.208333 %\n",
      "[epoch 0, iterations   600] loss: 1.711 accuracy: 29.500000 %\n",
      "[epoch 0, iterations   600] loss: 1.687 accuracy: 28.916667 %\n",
      "[epoch 0, iterations   700] loss: 1.615 accuracy: 30.821429 %\n",
      "[epoch 0, iterations   700] loss: 1.670 accuracy: 28.607143 %\n",
      "[epoch 0, iterations   700] loss: 1.701 accuracy: 30.678571 %\n",
      "[epoch 0, iterations   700] loss: 1.765 accuracy: 29.928571 %\n",
      "[epoch 0, iterations   800] loss: 1.725 accuracy: 31.375000 %\n",
      "[epoch 0, iterations   800] loss: 1.633 accuracy: 30.062500 %\n",
      "[epoch 0, iterations   800] loss: 1.557 accuracy: 32.343750 %\n",
      "[epoch 0, iterations   800] loss: 1.671 accuracy: 30.937500 %\n",
      "[epoch 0, iterations   900] loss: 1.668 accuracy: 32.194444 %[epoch 0, iterations   900] loss: 1.608 accuracy: 31.166667 %\n",
      "\n",
      "[epoch 0, iterations   900] loss: 1.623 accuracy: 33.222222 %\n",
      "[epoch 0, iterations   900] loss: 1.643 accuracy: 31.750000 %\n",
      "[2023-06-27 15:03:20,724] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:20,724] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:20,724] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:20,724] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:20,724] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:20,724] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:20,725] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:20,725] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[epoch 0, iterations  1000] loss: 1.570 accuracy: 33.200000 %\n",
      "[epoch 0, iterations  1000] loss: 1.649 accuracy: 32.200000 %\n",
      "[epoch 0, iterations  1000] loss: 1.644 accuracy: 33.750000 %\n",
      "[epoch 0, iterations  1000] loss: 1.594 accuracy: 32.800000 %\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1068\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1068\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1068\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1068\n",
      "[2023-06-27 15:03:21,041] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:21,041] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 0, iterations  1100] loss: 1.604 accuracy: 34.113636 %\n",
      "[epoch 0, iterations  1100] loss: 1.612 accuracy: 34.340909 %\n",
      "[epoch 0, iterations  1100] loss: 1.587 accuracy: 32.977273 %\n",
      "[epoch 0, iterations  1100] loss: 1.556 accuracy: 33.590909 %\n",
      "[epoch 0, iterations  1200] loss: 1.683 accuracy: 34.604167 %[epoch 0, iterations  1200] loss: 1.595 accuracy: 33.979167 %\n",
      "\n",
      "[epoch 0, iterations  1200] loss: 1.500 accuracy: 35.187500 %\n",
      "[epoch 0, iterations  1200] loss: 1.537 accuracy: 34.583333 %\n",
      "[epoch 0, iterations  1300] loss: 1.594 accuracy: 35.192308 %\n",
      "[epoch 0, iterations  1300] loss: 1.654 accuracy: 34.403846 %\n",
      "[epoch 0, iterations  1300] loss: 1.481 accuracy: 35.807692 %\n",
      "[epoch 0, iterations  1300] loss: 1.564 accuracy: 35.173077 %\n",
      "[epoch 0, iterations  1400] loss: 1.578 accuracy: 35.553571 %[epoch 0, iterations  1400] loss: 1.631 accuracy: 34.678571 %\n",
      "\n",
      "[epoch 0, iterations  1400] loss: 1.625 accuracy: 36.285714 %\n",
      "[epoch 0, iterations  1400] loss: 1.584 accuracy: 35.625000 %\n",
      "[epoch 0, iterations  1500] loss: 1.582 accuracy: 36.100000 %[epoch 0, iterations  1500] loss: 1.560 accuracy: 35.250000 %\n",
      "\n",
      "[epoch 0, iterations  1500] loss: 1.590 accuracy: 36.550000 %\n",
      "[epoch 0, iterations  1500] loss: 1.584 accuracy: 36.083333 %\n",
      "[2023-06-27 15:03:23,280] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:23,280] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:23,280] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:23,280] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:23,280] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:23,280] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:23,281] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:23,281] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:23,307] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1575\n",
      "[2023-06-27 15:03:23,307] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1575\n",
      "[2023-06-27 15:03:23,307] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1575\n",
      "[2023-06-27 15:03:23,307] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:23,307] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:23,307] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:23,308] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 1575\n",
      "[2023-06-27 15:03:23,308] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:23,308] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 0, iterations  1600] loss: 1.526 accuracy: 36.406250 %[epoch 0, iterations  1600] loss: 1.623 accuracy: 35.546875 %[epoch 0, iterations  1600] loss: 1.459 accuracy: 36.968750 %\n",
      "\n",
      "\n",
      "[epoch 0, iterations  1600] loss: 1.513 accuracy: 36.625000 %\n",
      "[epoch 0, iterations  1700] loss: 1.617 accuracy: 36.823529 %[epoch 0, iterations  1700] loss: 1.417 accuracy: 36.235294 %\n",
      "\n",
      "[epoch 0, iterations  1700] loss: 1.512 accuracy: 37.529412 %\n",
      "[epoch 0, iterations  1700] loss: 1.558 accuracy: 37.102941 %\n",
      "[epoch 0, iterations  1800] loss: 1.511 accuracy: 37.236111 %\n",
      "[epoch 0, iterations  1800] loss: 1.468 accuracy: 36.819444 %\n",
      "[epoch 0, iterations  1800] loss: 1.494 accuracy: 37.944444 %\n",
      "[epoch 0, iterations  1800] loss: 1.521 accuracy: 37.402778 %\n",
      "[epoch 0, iterations  1900] loss: 1.409 accuracy: 37.605263 %[epoch 0, iterations  1900] loss: 1.538 accuracy: 37.710526 %[epoch 0, iterations  1900] loss: 1.547 accuracy: 38.236842 %\n",
      "\n",
      "\n",
      "[epoch 0, iterations  1900] loss: 1.500 accuracy: 37.671053 %\n",
      "[epoch 0, iterations  2000] loss: 1.476 accuracy: 37.887500 %\n",
      "[epoch 0, iterations  2000] loss: 1.440 accuracy: 38.687500 %[epoch 0, iterations  2000] loss: 1.483 accuracy: 38.137500 %\n",
      "\n",
      "[2023-06-27 15:03:25,233] [INFO] [logging.py:69:log_dist] [Rank 0] step=2000, skipped=5, lr=[0.001], mom=[[0.8, 0.999]]\n",
      "[2023-06-27 15:03:25,234] [INFO] [timer.py:193:stop] 0/2000, SamplesPerSec=3744.7788408777374, MemAllocated=0.0GB, MaxMemAllocated=0.0GB\n",
      "[epoch 0, iterations  2000] loss: 1.556 accuracy: 37.887500 %\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:25,578] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:25,579] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2089\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2089\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2089\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2089\n",
      "[2023-06-27 15:03:25,636] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:25,637] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 0, iterations  2100] loss: 1.466 accuracy: 38.559524 %\n",
      "[epoch 0, iterations  2100] loss: 1.445 accuracy: 39.047619 %[epoch 0, iterations  2100] loss: 1.459 accuracy: 38.297619 %\n",
      "\n",
      "[epoch 0, iterations  2100] loss: 1.584 accuracy: 38.011905 %\n",
      "[epoch 0, iterations  2200] loss: 1.504 accuracy: 38.988636 %\n",
      "[epoch 0, iterations  2200] loss: 1.557 accuracy: 38.636364 %[epoch 0, iterations  2200] loss: 1.404 accuracy: 39.590909 %\n",
      "\n",
      "[epoch 0, iterations  2200] loss: 1.449 accuracy: 38.397727 %\n",
      "[epoch 0, iterations  2300] loss: 1.469 accuracy: 39.000000 %[epoch 0, iterations  2300] loss: 1.416 accuracy: 39.391304 %\n",
      "\n",
      "[epoch 0, iterations  2300] loss: 1.447 accuracy: 39.934783 %\n",
      "[epoch 0, iterations  2300] loss: 1.354 accuracy: 38.913043 %\n",
      "[epoch 0, iterations  2400] loss: 1.406 accuracy: 39.479167 %[epoch 0, iterations  2400] loss: 1.443 accuracy: 39.822917 %[epoch 0, iterations  2400] loss: 1.388 accuracy: 40.239583 %\n",
      "\n",
      "\n",
      "[epoch 0, iterations  2400] loss: 1.444 accuracy: 39.093750 %\n",
      "[epoch 0, iterations  2500] loss: 1.416 accuracy: 39.810000 %[epoch 0, iterations  2500] loss: 1.369 accuracy: 40.420000 %[epoch 0, iterations  2500] loss: 1.454 accuracy: 40.470000 %\n",
      "\n",
      "\n",
      "[epoch 0, iterations  2500] loss: 1.333 accuracy: 39.530000 %\n",
      "[2023-06-27 15:03:27,869] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:27,869] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:27,869] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:27,869] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:27,869] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:27,869] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:27,870] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:27,870] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[epoch 0, iterations  2600] loss: 1.369 accuracy: 40.269231 %\n",
      "[epoch 0, iterations  2600] loss: 1.372 accuracy: 40.721154 %\n",
      "[epoch 0, iterations  2600] loss: 1.360 accuracy: 40.903846 %\n",
      "[epoch 0, iterations  2600] loss: 1.463 accuracy: 39.711538 %\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2612\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2612\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2612\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:27,969] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 2612\n",
      "[2023-06-27 15:03:27,970] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:27,970] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 0, iterations  2700] loss: 1.431 accuracy: 40.638889 %\n",
      "[epoch 0, iterations  2700] loss: 1.491 accuracy: 40.935185 %\n",
      "[epoch 0, iterations  2700] loss: 1.407 accuracy: 41.222222 %\n",
      "[epoch 0, iterations  2700] loss: 1.494 accuracy: 39.944444 %\n",
      "[epoch 0, iterations  2800] loss: 1.427 accuracy: 40.919643 %[epoch 0, iterations  2800] loss: 1.387 accuracy: 41.348214 %\n",
      "[epoch 0, iterations  2800] loss: 1.394 accuracy: 41.580357 %\n",
      "\n",
      "[epoch 0, iterations  2800] loss: 1.494 accuracy: 40.142857 %\n",
      "[epoch 0, iterations  2900] loss: 1.334 accuracy: 41.775862 %[epoch 0, iterations  2900] loss: 1.439 accuracy: 41.103448 %\n",
      "[epoch 0, iterations  2900] loss: 1.323 accuracy: 41.931034 %\n",
      "\n",
      "[epoch 0, iterations  2900] loss: 1.527 accuracy: 40.344828 %\n",
      "[epoch 0, iterations  3000] loss: 1.412 accuracy: 41.958333 %[epoch 0, iterations  3000] loss: 1.337 accuracy: 41.425000 %\n",
      "[epoch 0, iterations  3000] loss: 1.329 accuracy: 42.325000 %\n",
      "\n",
      "[epoch 0, iterations  3000] loss: 1.490 accuracy: 40.541667 %\n",
      "[epoch 0, iterations  3100] loss: 1.381 accuracy: 42.330645 %[epoch 0, iterations  3100] loss: 1.477 accuracy: 41.717742 %\n",
      "[epoch 0, iterations  3100] loss: 1.439 accuracy: 42.508065 %\n",
      "\n",
      "[epoch 0, iterations  3100] loss: 1.356 accuracy: 40.911290 %\n",
      "[2023-06-27 15:03:30,224] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:30,224] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:30,224] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:30,224] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:30,224] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:30,224] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:30,225] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:30,225] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:30,608] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3128\n",
      "[2023-06-27 15:03:30,608] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3128\n",
      "[2023-06-27 15:03:30,608] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3128\n",
      "[2023-06-27 15:03:30,609] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:30,609] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:30,609] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:30,609] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3128\n",
      "[2023-06-27 15:03:30,609] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:30,609] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 1, iterations   100] loss: 1.380 accuracy: 50.000000 %\n",
      "[epoch 1, iterations   100] loss: 1.373 accuracy: 49.000000 %[epoch 1, iterations   100] loss: 1.298 accuracy: 53.000000 %\n",
      "\n",
      "[epoch 1, iterations   100] loss: 1.371 accuracy: 50.500000 %\n",
      "[epoch 1, iterations   200] loss: 1.421 accuracy: 49.375000 %\n",
      "[epoch 1, iterations   200] loss: 1.370 accuracy: 50.000000 %\n",
      "[epoch 1, iterations   200] loss: 1.312 accuracy: 49.250000 %\n",
      "[epoch 1, iterations   200] loss: 1.375 accuracy: 50.375000 %\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3405\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3405\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3405\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 3405\n",
      "[2023-06-27 15:03:31,807] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0\n",
      "[2023-06-27 15:03:31,807] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0\n",
      "[epoch 1, iterations   300] loss: 1.397 accuracy: 49.500000 %\n",
      "[epoch 1, iterations   300] loss: 1.430 accuracy: 49.583333 %\n",
      "[epoch 1, iterations   300] loss: 1.316 accuracy: 50.916667 %\n",
      "[epoch 1, iterations   300] loss: 1.320 accuracy: 50.916667 %\n",
      "[epoch 1, iterations   400] loss: 1.310 accuracy: 50.000000 %\n",
      "[epoch 1, iterations   400] loss: 1.308 accuracy: 49.937500 %\n",
      "[epoch 1, iterations   400] loss: 1.312 accuracy: 51.312500 %\n",
      "[epoch 1, iterations   400] loss: 1.325 accuracy: 50.750000 %\n",
      "[epoch 1, iterations   500] loss: 1.238 accuracy: 50.700000 %[epoch 1, iterations   500] loss: 1.396 accuracy: 50.850000 %\n",
      "[epoch 1, iterations   500] loss: 1.309 accuracy: 50.450000 %\n",
      "\n",
      "[epoch 1, iterations   500] loss: 1.272 accuracy: 52.050000 %\n",
      "[epoch 1, iterations   600] loss: 1.269 accuracy: 51.791667 %\n",
      "[epoch 1, iterations   600] loss: 1.374 accuracy: 50.791667 %\n",
      "[epoch 1, iterations   600] loss: 1.375 accuracy: 49.958333 %\n",
      "[epoch 1, iterations   600] loss: 1.294 accuracy: 52.416667 %\n",
      "[epoch 1, iterations   700] loss: 1.285 accuracy: 52.035714 %[epoch 1, iterations   700] loss: 1.336 accuracy: 49.785714 %[epoch 1, iterations   700] loss: 1.315 accuracy: 51.178571 %\n",
      "\n",
      "\n",
      "[epoch 1, iterations   700] loss: 1.421 accuracy: 51.964286 %\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 2048.0 to 4096.0\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 2048.0 to 4096.0\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 2048.0 to 4096.0\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:34,006] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 2048.0 to 4096.0\n",
      "[epoch 1, iterations   800] loss: 1.219 accuracy: 50.875000 %[epoch 1, iterations   800] loss: 1.446 accuracy: 51.468750 %\n",
      "\n",
      "[epoch 1, iterations   800] loss: 1.248 accuracy: 52.281250 %\n",
      "[epoch 1, iterations   800] loss: 1.310 accuracy: 51.718750 %\n",
      "[2023-06-27 15:03:34,416] [INFO] [logging.py:69:log_dist] [Rank 0] step=4000, skipped=9, lr=[0.001], mom=[[0.8, 0.999]]\n",
      "[2023-06-27 15:03:34,417] [INFO] [timer.py:193:stop] 0/4000, SamplesPerSec=3733.3049754484496, MemAllocated=0.0GB, MaxMemAllocated=0.0GB\n",
      "[epoch 1, iterations   900] loss: 1.371 accuracy: 52.166667 %[epoch 1, iterations   900] loss: 1.330 accuracy: 51.583333 %[epoch 1, iterations   900] loss: 1.311 accuracy: 51.055556 %\n",
      "\n",
      "\n",
      "[epoch 1, iterations   900] loss: 1.362 accuracy: 51.388889 %\n",
      "[epoch 1, iterations  1000] loss: 1.327 accuracy: 51.450000 %\n",
      "[epoch 1, iterations  1000] loss: 1.363 accuracy: 51.300000 %\n",
      "[epoch 1, iterations  1000] loss: 1.341 accuracy: 52.025000 %\n",
      "[epoch 1, iterations  1000] loss: 1.279 accuracy: 51.725000 %\n",
      "[epoch 1, iterations  1100] loss: 1.315 accuracy: 51.613636 %[epoch 1, iterations  1100] loss: 1.216 accuracy: 52.386364 %\n",
      "\n",
      "[epoch 1, iterations  1100] loss: 1.311 accuracy: 51.659091 %\n",
      "[epoch 1, iterations  1100] loss: 1.235 accuracy: 52.409091 %\n",
      "[epoch 1, iterations  1200] loss: 1.251 accuracy: 51.937500 %[epoch 1, iterations  1200] loss: 1.315 accuracy: 52.395833 %\n",
      "[epoch 1, iterations  1200] loss: 1.424 accuracy: 51.395833 %\n",
      "\n",
      "[epoch 1, iterations  1200] loss: 1.318 accuracy: 52.125000 %\n",
      "[2023-06-27 15:03:36,212] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:36,212] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:36,212] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:36,212] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:36,212] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:36,212] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:36,213] [INFO] [fused_optimizer.py:392:_update_scale] No Grad overflow for 500 iterations\n",
      "[2023-06-27 15:03:36,213] [INFO] [fused_optimizer.py:394:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
      "[2023-06-27 15:03:36,231] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 4410\n",
      "[2023-06-27 15:03:36,231] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 4410\n",
      "[2023-06-27 15:03:36,231] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 4410\n",
      "[2023-06-27 15:03:36,231] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:36,231] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:36,231] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:36,232] [INFO] [fused_optimizer.py:382:_update_scale] \n",
      "Grad overflow on iteration 4410\n",
      "[2023-06-27 15:03:36,232] [INFO] [fused_optimizer.py:383:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
      "[2023-06-27 15:03:36,232] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[epoch 1, iterations  1300] loss: 1.339 accuracy: 51.673077 %\n",
      "[epoch 1, iterations  1300] loss: 1.160 accuracy: 52.057692 %\n",
      "[epoch 1, iterations  1300] loss: 1.448 accuracy: 52.019231 %\n",
      "[epoch 1, iterations  1300] loss: 1.245 accuracy: 52.250000 %\n",
      "[epoch 1, iterations  1400] loss: 1.338 accuracy: 52.089286 %[epoch 1, iterations  1400] loss: 1.323 accuracy: 51.660714 %[epoch 1, iterations  1400] loss: 1.315 accuracy: 52.053571 %\n",
      "\n",
      "\n",
      "[epoch 1, iterations  1400] loss: 1.308 accuracy: 52.285714 %\n"
     ]
    }
   ],
   "source": [
    "# run the training on 4 GPUs with Data parallel\n",
    "!deepspeed --num_gpus=4 /dli/code/moe/cifar10_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config /dli/code/moe/ds_config.json \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name='zero0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the same run on a SLURM based cluster, simply write the SBATCH script allocating the desired resources and invoke the same DeepSpeed command. \n",
    "\n",
    "Run the next cell to create the SBATCH script allocating 2 nodes to run the previous training with DeepSpeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /dli/code/run_cifar10_deepspeed_2Nodes.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_ds\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "# Number of nodes\n",
    "NUM_NODES=2\n",
    "# Number of GPUs per node\n",
    "NUM_GPUS=2\n",
    "\n",
    "\n",
    "deepspeed --num_nodes=${NUM_NODES} --hostfile /dli/code/moe/hostfile --num_gpus=${NUM_GPUS} /dli/code/moe/cifar10_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config /dli/code/moe/ds_config.json \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name='zero0_sbatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's submit the previous sbatch script [run_cifar10_deepspeed_2Nodes.sh](./code/run_cifar10_deepspeed_2Nodes.sh) and check the SLURM queue using the `squeue` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the 2 nodes jobs\n",
    "!sbatch /dli/code/run_cifar10_deepspeed_2Nodes.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU utilization on the master node\n",
    "!sleep 10\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3 Zero Redundancy Optimizer \n",
    "\n",
    "[ZeRO](https://www.deepspeed.ai/tutorials/zero/) reduces the memory consumption of each GPU by distributing the model's training states (weights, gradients, and optimizer states) across the available devices. ZeRO is implemented as 3 accumulative stages:\n",
    "\n",
    "- **ZeRO-1:** The optimizer states are partitioned across the processes, so that each process updates only its partition. For instance, the Adam optimizer will store 32-bit weights, and the first, and second moment estimates.\n",
    "- **ZeRO-2:** In addition to Zero 1, the reduced 32-bit gradients for updating the model weights are also partitioned such that each process retains only the gradients corresponding to its portion of the optimizer states.\n",
    "- **ZeRO-3:** In addition to Zero 2, the 16-bit model parameters are partitioned across the processes. ZeRO-3 will automatically collect and partition them during the forward and backward passes. ZeRO-3 also includes the [ZeRO-Infinity](https://arxiv.org/pdf/2104.07857.pdf) engine that offloads to both CPU and NVMe memory for memory savings.\n",
    "\n",
    "```\n",
    "{\n",
    " \"zero_optimization\": {\n",
    "    \"stage\": [0|1|2|3],\n",
    "    \"allgather_partitions\": [true|false],\n",
    "    \"allgather_bucket_size\": 5e8,\n",
    "    \"overlap_comm\": false,\n",
    "    \"reduce_scatter\": [true|false],\n",
    "    \"reduce_bucket_size\": 5e8,\n",
    "    \"contiguous_gradients\" : [true|false],\n",
    "    \"offload_param\": {\n",
    "      ...\n",
    "    },\n",
    "    \"offload_optimizer\": {\n",
    "      ...\n",
    "    },\n",
    "    \"stage3_max_live_parameters\" : 1e9,\n",
    "    \"stage3_max_reuse_distance\" : 1e9,\n",
    "    \"stage3_prefetch_bucket_size\" : 5e8,\n",
    "    \"stage3_param_persistence_threshold\" : 1e6,\n",
    "    \"sub_group_size\" : 1e12,\n",
    "    \"elastic_checkpoint\" : [true|false],\n",
    "    \"stage3_gather_16bit_weights_on_model_save\": [true|false],\n",
    "    \"ignore_unused_parameters\": [true|false]\n",
    "    \"round_robin_gradients\": [true|false]\n",
    "    }\n",
    "  }\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"https://www.microsoft.com/en-us/research/uploads/prod/2020/02/Turing-Animation.mp4?_=1\" width=\"560\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to illustrate the advantages of ZeRO optimizer in memory saving, let's scale our CNN model to a larger neural network. We  replaced the tiny CNN network with the Resnet152 model with 11 million parameters in the [large_model_deepspeed.py](./code/moe/large_model_deepspeed.py).\n",
    "\n",
    "\n",
    "The following figure shows the CPU usage via [htop](https://htop.dev/) command and the GPU 0 memory profiled using Pytorch Profiler (available on the Tensorboard) for the *resnet152* training step. We can see a comparison between no ZeRO and ZeRO stage 3 + Offload. The memory peak required per GPU without ZeRO optimizer is about 1.5GB, while offloading the parameters to the CPU with ZeRO-3 uses only 845MB. On the other hand, the time per step increased significantly from 500ms to 7000ms!\n",
    "\n",
    "ZeRO infinity allows sacling to larger models when the number of GPUs are limited, but this comes with an additional training time corresponding to data movement.\n",
    "<img src=\"images/zero_memory.png\" width=\"1250\" />\n",
    "\n",
    "\n",
    "Let's run the Zero stage 3 optimizer and enable CPU offload of the parameters. We have prepared the configuration file. Notice that we have increased the training batch size per GPU to 512. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DeepSpeed config file for Zero stage 3 Offload\n",
    "!cat /dli/code/moe/ds_config_stage_3.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's download the resnet152 model. More information about it can be found [here](https://pytorch.org/hub/pytorch_vision_resnet/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet152\", force_reload=True, pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to run the *resnet152* model training on the CIFAR-10 dataset. Notice that in these experiments, our focus is memory consumption as opposed to model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!deepspeed --num_gpus=4 /dli/code/moe/large_model_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config /dli/code/moe/ds_config_stage_3.json \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name='zero_resnet152_stage3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Execute the next cell to create a link to Tensorboard in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: ZeRO Stage 1\n",
    "\n",
    "Compare ZeRO Stage 1 execution time and GPU/CPU memory to no ZeRO and ZeRO Stage 3 + Offload. We have already prepared the DeepSpeed configuration file. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DeepSpeed config file for Zero stage 1 \n",
    "!cat /dli/code/moe/ds_config_stage_1.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to run the *resnet152* model training on the CIFAR-10 dataset with ZeRO Stage1. Replace the `FIXME` with the corresponding arguments. If you get stuck, you can look at the [solution](solutions/ex5.2.4.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!deepspeed --num_gpus=4 /dli/code/moe/large_model_deepspeed.py \\\n",
    "    --deepspeed \\\n",
    "    --deepspeed_config #FIXEME \\\n",
    "    --profile-execution=True \\\n",
    "    --profile-name=#FIXEME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the run without ZeRO, Stage 1 allows to reduce the GPU memory usage from about 1.5GB to 1GB as it partitions the optimizer states across 4 GPUs meaning that each GPU is responsible for keeping in memory a part of the optimizer states and communicate them when necessary to others. In this case, no significant extra time is observed to run the step with ZeRO Stage 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: 5.2.4  Autotuning\n",
    "\n",
    "When designing training experiments, it is hard to know what are the best configurations (such as micro-batch size) that fully utilize the hardware and achieve a high throughput number. Usually, configuration exploration is performed manually. This tuning process can be painful, time-consuming and the configurations are hardware-dependent. The DeepSpeed Autotuner automatically discovers the optimal DeepSpeed configuration parameters that optimizes for training speed.\n",
    "To launch the autotuning, add `--autotuning run` command to the training script and enable it on the configuration file as follows: \n",
    "\n",
    "```\n",
    "{\n",
    "  \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "\n",
    "  \"autotuning\": {\n",
    "    \"enabled\": true,\n",
    "    \"arg_mappings\": {\n",
    "      \"train_micro_batch_size_per_gpu\": \"--batch_size\"    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "The arg_mappings dictionary autotuning section of the DeepSpeed configuration file provides the naming mappings between the parameters in DeepSpeed configuration and the training script arguments. It is also possible restrict the search space to a list of values by replacing \"auto\" with a vector of possible values to be evaluated. \n",
    "\n",
    "To learn more about the Autotuning feature, check the [DeepSpeed documentation](https://www.deepspeed.ai/tutorials/autotuning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "Before moving on, we need to make sure no jobs are still running or waiting in the queue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are still jobs running or pending, execute the following cell to cancel all the admin user's jobs using the `scancel` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel admin user jobs\n",
    "!scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will see Mixture of Expert (MOE)configurations. Move on to [06_MOE_alternative_models.ipynb](06_MOE_alternative_models.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
