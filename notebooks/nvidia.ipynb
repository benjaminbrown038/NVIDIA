{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHSiYdYI5IBWYpKWJ26dtS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/NVIDIA/blob/main/notebooks/nvidia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NVIDIA\n",
        "\n",
        "- Multi-GPU Training Strategies\n",
        "- Unoptimized deployment of GPT-J\n",
        "- Optimizing inference with NVIDIA FasterTransformer library\n",
        "- Multi-Node Distributed Training Strategies\n",
        "- GPT_LM_pretrainings_optimizations\n",
        "- GPT-J deployment with NVIDIA FasterTransformer and Triton Inference server\n",
        "- Multi-Nodes Distributed Training for Computer Vision\n",
        "- Mixture of Experts (MoE)\n",
        "- Sequence Data"
      ],
      "metadata": {
        "id": "c32iwcGm_Ge0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-GPU Training Strategies"
      ],
      "metadata": {
        "id": "ow1S9pcr_Ghr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!squeue"
      ],
      "metadata": {
        "id": "1HHVdzXt_GtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scancel -u $USER"
      ],
      "metadata": {
        "id": "d-lt2xl7B5_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!squeue"
      ],
      "metadata": {
        "id": "ybL6rm60B6Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /dli/code/pretrain_gpt_1GPU.sh"
      ],
      "metadata": {
        "id": "rgUy3bAoB6Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<pre>\n",
        "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
        "   Step 2: Run an interactive session: <font color=\"green\">srun -N 1 --pty /bin/bash</font>\n",
        "   Step 3: Run the megatron gpt3 pretraining on 1 GPU: <font color=\"green\">bash ./code/pretrain_gpt_1GPU.sh</font>\n",
        "</pre>"
      ],
      "metadata": {
        "id": "bIDl5hUMB6Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!squeue"
      ],
      "metadata": {
        "id": "Wi-W1ZRwB6LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sleep 6m\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "RfNYdRcqB6N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep iteration /dli/megatron/logs/log_1GPU.txt"
      ],
      "metadata": {
        "id": "L2nLXq4hB6Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /dli/megatron/checkpoints/*"
      ],
      "metadata": {
        "id": "OMVh502HB6Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /dli/code/pretrain_gpt_2GPU.sh"
      ],
      "metadata": {
        "id": "8v_PjaY1CkFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash"
      ],
      "metadata": {
        "id": "49QZ11gdCmTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distributed training args\n",
        "NNODES=1\n",
        "GPUS_PER_NODE=#FIXEME         # <--- CHANGE HERE\n",
        "TP_SIZE=1\n",
        "PP_SIZE=1\n",
        "\n",
        "# Distributed training\n",
        "MICRO_BATCH_SIZE=2\n",
        "GLOBAL_BATCH_SIZE=#FIXEME    # <--- CHANGE HERE\n",
        "\n",
        "# Model architecture\n",
        "NLAYERS=12\n",
        "NHIDDEN=768\n",
        "NHEADS=32\n",
        "SEQ_LEN=1024\n",
        "VOCAB_SIZE=50257\n",
        "\n",
        "# Data Paths\n",
        "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
        "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
        "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
        "\n",
        "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
        "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
        "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
        "LOGS_PATH=/dli/megatron/logs\n",
        "NAME=\"log_2GPU\"\n",
        "\n",
        "# SLURM args\n",
        "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
        "MASTER_PORT=6000\n",
        "\n",
        "OPTIMIZER_ARGS=\" \\\n",
        "            --optimizer adam \\\n",
        "            --adam-beta1 0.9 \\\n",
        "            --adam-beta2 0.95 \\\n",
        "            --adam-eps 1e-8 \\\n",
        "            --lr 6e-5 \\\n",
        "            --min-lr 6e-6 \\\n",
        "            --lr-decay-style cosine \\\n",
        "            --lr-decay-iters 800 \\\n",
        "            --lr-warmup-fraction .01 \\\n",
        "            --clip-grad 1.0 \\\n",
        "            --weight-decay 1e-1 \\\n",
        "            --exit-duration-in-mins 1190 \\\n",
        "            \"\n",
        "\n",
        "GPT_ARGS=\" \\\n",
        "            --num-layers $NLAYERS \\\n",
        "            --hidden-size $NHIDDEN \\\n",
        "            --num-attention-heads $NHEADS \\\n",
        "            --seq-length $SEQ_LEN \\\n",
        "            --max-position-embeddings $SEQ_LEN \\\n",
        "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
        "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
        "            --train-iters 100 \\\n",
        "            --vocab-file $VOCAB_FILE \\\n",
        "            --merge-file $MERGE_FILE \\\n",
        "            --init-method-std 0.006 \\\n",
        "            $OPTIMIZER_ARGS \\\n",
        "            $EXIT_OPTS \\\n",
        "            \"\n",
        "\n",
        "OUTPUT_ARGS=\" \\\n",
        "            --log-interval 10 \\\n",
        "            --save-interval 300 \\\n",
        "            --eval-interval 1000 \\\n",
        "            --eval-iters 10 \\\n",
        "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
        "            --tensorboard-queue-size 1 \\\n",
        "            --log-timers-to-tensorboard \\\n",
        "            --log-batch-size-to-tensorboard \\\n",
        "            --log-validation-ppl-to-tensorboard \\\n",
        "            \"\n",
        "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
        "            --nproc_per_node $GPUS_PER_NODE \\\n",
        "            --nnodes $NNODES \\\n",
        "            --master_addr $MASTER_ADDR \\\n",
        "            --master_port $MASTER_PORT \\\n",
        "\n",
        "export CMD=\" \\\n",
        "            /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
        "            --tensor-model-parallel-size $TP_SIZE \\\n",
        "            --pipeline-model-parallel-size $PP_SIZE \\\n",
        "            $GPT_ARGS \\\n",
        "            $OUTPUT_ARGS \\\n",
        "            --save $CHECKPOINT_PATH \\\n",
        "            --data-path $DATA_PATH \\\n",
        "            --data-impl mmap \\\n",
        "            --split 949,50,1 \\\n",
        "            --distributed-backend nccl \\\n",
        "            \"\n",
        "\n",
        "bash -c '$LAUNCHER  $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
      ],
      "metadata": {
        "id": "XUX5aINCB6Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<pre>\n",
        "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
        "   Step 2: Run an interactive session: <font color=\"green\">srun -N 1 --pty /bin/bash</font>\n",
        "   Step 3: Run the megatron gpt3 pretraining on 1 GPU: <font color=\"green\">bash ./code/pretrain_gpt_2GPU.sh</font>\n",
        "</pre>"
      ],
      "metadata": {
        "id": "piSb82SmB6ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!squeue"
      ],
      "metadata": {
        "id": "t57bKykjB6b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "CjDx5PtzCYzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep iteration /dli/megatron/logs/log_2GPU.txt"
      ],
      "metadata": {
        "id": "k5v4ZLO9CY43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /dli/megatron/checkpoints/*"
      ],
      "metadata": {
        "id": "VfoEp9KECY7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!squeue"
      ],
      "metadata": {
        "id": "iRN51DWqCY-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scancel -u $USER"
      ],
      "metadata": {
        "id": "f3Gv05A5CZBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!squeue"
      ],
      "metadata": {
        "id": "4ExOQCzaCZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qoh89jrB6e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unoptimized deployment of GPT-J"
      ],
      "metadata": {
        "id": "NEM4qYK4_GzD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4FlvlTI_G88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing inference with NVIDIA FasterTransformer library"
      ],
      "metadata": {
        "id": "oUU4U00__HG0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VX4Z4tXU_HNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Node Distributed Training Strategies"
      ],
      "metadata": {
        "id": "9JC_LMeLAK8E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kluL7Iwd_HVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT LM Pretrainings Optimizations"
      ],
      "metadata": {
        "id": "ZtrPzG_3AL2E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGQI1C5y_HdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-J deployment with NVIDIA FasterTransformer and Triton Inference server"
      ],
      "metadata": {
        "id": "5DLouxOSAMf8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TntaMHRYAMl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Nodes Distributed Training for Computer Vision"
      ],
      "metadata": {
        "id": "A87MiDllAMqe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJcci-QvAMu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mixture of Experts (MoE)"
      ],
      "metadata": {
        "id": "U5_C9PNKAMze"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsxOJ-iWAM4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequence Data"
      ],
      "metadata": {
        "id": "ldxm_IYkAM8F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iinS-8h_ANVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}